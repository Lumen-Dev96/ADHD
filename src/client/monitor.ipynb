{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9445cd2a-51b8-476c-8b9b-7e0ced507d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-01 17:31:34.316952: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "weight_decay is not a valid argument, kwargs should be empty  for `optimizer_experimental.Optimizer`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 228\u001b[0m\n\u001b[1;32m    226\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    227\u001b[0m model_path \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpb_path\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 228\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m########### LOAD MODEL ###############\u001b[39;00m\n\u001b[1;32m    233\u001b[0m source1 \u001b[38;5;241m=\u001b[39m ColumnDataSource(data\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m: x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m: y_data[\u001b[38;5;241m1\u001b[39m]})\n",
      "File \u001b[0;32m~/Conda/miniconda3/envs/ADHD/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Conda/miniconda3/envs/ADHD/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:115\u001b[0m, in \u001b[0;36m_BaseOptimizer._process_kwargs\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated in `optimizer_experimental.Optimizer`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, please check the docstring for valid arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    112\u001b[0m         k,\n\u001b[1;32m    113\u001b[0m     )\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid argument, kwargs should be empty \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for `optimizer_experimental.Optimizer`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: weight_decay is not a valid argument, kwargs should be empty  for `optimizer_experimental.Optimizer`."
     ]
    }
   ],
   "source": [
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource, Segment, Range1d\n",
    "from bokeh.layouts import layout\n",
    "from bokeh.io import push_notebook, show, output_notebook\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import sys\n",
    "import pandas as pd\n",
    "import paho.mqtt.client as mqtt\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "from math import *\n",
    "import random\n",
    "import _thread\n",
    "import yaml\n",
    "\n",
    "\n",
    "\n",
    "# 更新函數，每次呼叫時更新數據\n",
    "def update(message):\n",
    "    global x, y_data, grap_id, rawData, record_count\n",
    "    \n",
    "    # 解碼 MQTT 數據\n",
    "    if test_mode:\n",
    "        data = message\n",
    "    else:\n",
    "        payload = message.payload.decode()\n",
    "        data = json.loads(payload)\n",
    "\n",
    "    \n",
    "    mqData = np.array(data)\n",
    "\n",
    "    times = mqData[:, 0]\n",
    "    channel1 = mqData[:, 1]\n",
    "    channel2 = mqData[:, 2]\n",
    "    channel3 = mqData[:, 3]\n",
    "    channel4 = mqData[:, 4]\n",
    "    channel5 = mqData[:, 5]\n",
    "    channel6 = mqData[:, 6]\n",
    "    channel7 = mqData[:, 7]\n",
    "    channel8 = mqData[:, 8]\n",
    "    channel9 = mqData[:, 9]\n",
    "    channel10 = mqData[:, 10]\n",
    "    channel11 = mqData[:, 11]\n",
    "    channel12 = mqData[:, 12]\n",
    "\n",
    "    rawData.append(mqData)\n",
    "\n",
    "\n",
    "    \n",
    "    ### 使用模型进行预测 ###\n",
    "\n",
    "    # 使用測試隨機數\n",
    "    # ranges = np.array([[1.7, 2], [6.7, 7], [-7, -6.6], [-4, 2], [-2, 2], [-8, -3], [0, 0.3], [9, 9.3], [-4.3, -4], [0, 5], [-2, 2], [-6, -4]])\n",
    "    # 使用 numpy.random.uniform 生成具有不同範圍的數據\n",
    "    # dataForTest = np.column_stack([np.random.uniform(low=low, high=high, size=30) for low, high in ranges])\n",
    "    # print('-----------------')\n",
    "    # dataForTest = dataForTest[np.newaxis, ...]\n",
    "    # print('transforming test random data shape:', dataForTest.shape)\n",
    "    # print('data for test:', dataForTest)\n",
    "\n",
    "\n",
    "    # 使用訓練數據展示結果\n",
    "    # dataForTrain = trained_data_x[record_count * data_length : record_count * data_length + data_length, :]\n",
    "    # dataForTrain = dataForTrain[np.newaxis, ...]\n",
    "    # print('transforming train data shape:', dataForTrain.shape)\n",
    "    # print('data for train:', dataForTrain)\n",
    "\n",
    "    if record_count > 1:\n",
    "        npRawData = np.concatenate(rawData, axis=0)\n",
    "        start = record_count - 1\n",
    "        fifoData = np.empty((30, 30, 12), dtype=float)\n",
    "        for i in range(window_size):\n",
    "            tmp = npRawData[start * window_size + i : start * window_size + window_size + i, 1:]\n",
    "            np.append(fifoData, tmp[np.newaxis, ...].astype(float))\n",
    "    \n",
    "        # print('transforming fifo data shape:', fifoData.shape)\n",
    "        # print('fifo:', fifoData)\n",
    "        y_pred = model.predict(fifoData)\n",
    "        predictions.append(y_pred)\n",
    "\n",
    "        # 将预测结果转换为 NumPy 数组\n",
    "        # predictionsNp = np.array(predictions)\n",
    "        predictionsNp = np.array(y_pred)\n",
    "        predictionsNp = predictionsNp.flatten()\n",
    "        print(predictionsNp)\n",
    "        print('---------')\n",
    "        print(y_pred)\n",
    "        # print('predictoinNp:', predictionsNp)\n",
    "        # print('------------------')\n",
    "        # print('predictions shape:', predictionsNp.shape)\n",
    "        # 提取预测类别的最大概率 >0.5 => 1, <0.5 => 0\n",
    "        # predicted_classes = predictionsNp[-1]\n",
    "        # 只會有一個結果, 值為 0 或者 1\n",
    "        # print(predicted_classes[0])\n",
    "        # prediction_label = round(predicted_classes[0])\n",
    "        # print('predicted_classes', predicted_classes)\n",
    "        # print('prediction_label', prediction_label)\n",
    "        source13.stream({'x':np.arange(grap_id, grap_id + window_size), 'y': predictionsNp})\n",
    "\n",
    "\n",
    "\n",
    "    # 更新數據源的數據\n",
    "    grap_id += data_length\n",
    "\n",
    "    record_count = record_count + 1\n",
    "\n",
    "\n",
    "    # 更新數據源的數據\n",
    "    grap_id += data_length\n",
    "    source1.stream({'x':np.arange(grap_id, grap_id + data_length), 'y':channel1})\n",
    "    source2.stream({'x':np.arange(grap_id, grap_id + data_length), 'y':channel2})\n",
    "    source3.stream({'x':np.arange(grap_id, grap_id + data_length), 'y':channel3})\n",
    "    source4.stream({'x':np.arange(grap_id, grap_id + data_length), 'y':channel4})\n",
    "    source5.stream({'x':np.arange(grap_id, grap_id + data_length), 'y':channel5})\n",
    "    source6.stream({'x':np.arange(grap_id, grap_id + data_length), 'y':channel6})\n",
    "    source7.stream({'x':np.arange(grap_id, grap_id + data_length), 'y':channel7})\n",
    "    source8.stream({'x':np.arange(grap_id, grap_id + data_length), 'y':channel8})\n",
    "    source9.stream({'x':np.arange(grap_id, grap_id + data_length), 'y':channel9})\n",
    "    source10.stream({'x':np.arange(grap_id, grap_id + data_length), 'y':channel10})\n",
    "    source11.stream({'x':np.arange(grap_id, grap_id + data_length), 'y':channel11})\n",
    "    source12.stream({'x':np.arange(grap_id, grap_id + data_length), 'y':channel12})\n",
    "\n",
    "\n",
    "    if record_count % 1000 == 0:\n",
    "        exportCSV()\n",
    "\n",
    "    push_notebook()\n",
    "\n",
    "    \n",
    "\n",
    "def exportCSV():\n",
    "    global rawData\n",
    "    csvData = np.concatenate(rawData, axis=0)\n",
    "    timestamps = csvData[:, 0]\n",
    "    ax1 = csvData[:, 1]\n",
    "    ay1 = csvData[:, 2]\n",
    "    az1 = csvData[:, 3]\n",
    "    gx1 = csvData[:, 4]\n",
    "    gy1 = csvData[:, 5]\n",
    "    gz1 = csvData[:, 6]\n",
    "\n",
    "    ax2 = csvData[:, 7] \n",
    "    ay2 = csvData[:, 8]\n",
    "    az2 = csvData[:, 9]\n",
    "    gx2 = csvData[:, 10]\n",
    "    gy2 = csvData[:, 11]\n",
    "    gz2 = csvData[:, 12]\n",
    "\n",
    "    # 将时间戳转换为本地时间元组\n",
    "    # new_times = np.vectorize(transformTimestamps)(timestamps)\n",
    "\n",
    "    # dictionary of lists\n",
    "    dict = {'Time': timestamps, 'Ax1': ax1, 'Ay1': ay1, 'Az1': az1, 'Gx1': gx1, 'Gy1': gy1, 'Gz1': gz1, 'Ax2': ax2, 'Ay2': ay2, 'Az2': az2, 'Gx2': gx2, 'Gy2': gy2, 'Gz2': gz2}\n",
    "        \n",
    "    df = pd.DataFrame(dict)\n",
    "    filename = 'output.csv'\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "\n",
    "def on_connect(client, userdata, flags, rc):\n",
    "    if rc == 0:\n",
    "        print(\"Connected to MQTT broker\")\n",
    "    else:\n",
    "        print(\"Failed to connect, return code %d\\n\", rc)\n",
    "\n",
    "def on_message(client, userdata, message):\n",
    "    print(\"Received data from esp32 via MQTT\")\n",
    "    update(message)\n",
    "    # print(\"Received message on topic %s: %s\" % (message.topic, message.payload.decode()))\n",
    "\n",
    "\n",
    "def connect_mqtt_server():\n",
    "    # 连接MQTT代理\n",
    "    # broker_address = \"broker.emqx.io\"\n",
    "    broker_address = config['mqtt']['broker_address']\n",
    "    # broker_address = \"broker.mqttdashboard.com\"\n",
    "    # broker_address = \"test.mosquitto.org\"\n",
    "    port = config['mqtt']['port']\n",
    "    username = config['mqtt']['username']\n",
    "    password = config['mqtt']['password']\n",
    "\n",
    "    client = mqtt.Client()\n",
    "    client.username_pw_set(username, password)\n",
    "    client.on_connect = on_connect\n",
    "    client.on_message = on_message\n",
    "\n",
    "    client.connect(broker_address, port)\n",
    "\n",
    "    # 订阅消息\n",
    "    client.subscribe(topic)\n",
    "\n",
    "    _thread.start_new_thread(client.loop_forever, (1,))\n",
    "\n",
    "\n",
    "# 初始化數據/設定\n",
    "with open('./config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "data_length = config['data']['length']\n",
    "data_channels = config['data']['channels']\n",
    "window_size = config['data']['window_size']\n",
    "trained_data_path = config['data']['train_data_path']\n",
    "topic = config['mqtt']['topic']\n",
    "\n",
    "\n",
    "x = np.arange(data_length)\n",
    "\n",
    "y_data = [np.zeros(data_length) for _ in range(data_channels + 1)]\n",
    "\n",
    "grap_id = 0\n",
    "\n",
    "record_count = 0\n",
    "\n",
    "rawData = []\n",
    "\n",
    "\n",
    "\n",
    "trained_data = pd.read_csv(trained_data_path + 'a1_1.csv')\n",
    "trained_data_x = trained_data.iloc[:, 1:-1].values\n",
    "\n",
    "\n",
    "########### LOAD MODEL ###############\n",
    "predictions = []\n",
    "model_path = config['model']['pb_path']\n",
    "model = load_model(model_path, compile=False)\n",
    "model.compile()\n",
    "########### LOAD MODEL ###############\n",
    "\n",
    "\n",
    "\n",
    "source1 = ColumnDataSource(data={'x': x, 'y': y_data[1]})\n",
    "source2 = ColumnDataSource(data={'x': x, 'y': y_data[2]})\n",
    "source3 = ColumnDataSource(data={'x': x, 'y': y_data[3]})\n",
    "source4 = ColumnDataSource(data={'x': x, 'y': y_data[4]})\n",
    "source5 = ColumnDataSource(data={'x': x, 'y': y_data[5]})\n",
    "source6 = ColumnDataSource(data={'x': x, 'y': y_data[6]})\n",
    "\n",
    "source7 = ColumnDataSource(data={'x': x, 'y': y_data[7]})\n",
    "source8 = ColumnDataSource(data={'x': x, 'y': y_data[8]})\n",
    "source9 = ColumnDataSource(data={'x': x, 'y': y_data[9]})\n",
    "source10 = ColumnDataSource(data={'x': x, 'y': y_data[10]})\n",
    "source11 = ColumnDataSource(data={'x': x, 'y': y_data[11]})\n",
    "source12 = ColumnDataSource(data={'x': x, 'y': y_data[12]})\n",
    "source13 = ColumnDataSource(data={'x': np.arange(1), 'y': np.zeros(1)})\n",
    "\n",
    "\n",
    "\n",
    "# 創建 Bokeh 的線型圖\n",
    "plots = []\n",
    "plot1 = figure(height=150, title=\"MPU1\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "line_ax1 = plot1.line('x', 'y', source=source1, line_width=2, line_alpha=0.8, line_color='black', legend_label='AX1')\n",
    "line_ay1 = plot1.line('x', 'y', source=source2, line_width=2, line_alpha=0.8, line_color='blue', legend_label='AY1')\n",
    "line_az1 = plot1.line('x', 'y', source=source3, line_width=2, line_alpha=0.8, line_color='red', legend_label='AZ1')\n",
    "line_gx1 = plot1.line('x', 'y', source=source4, line_width=2, line_alpha=0.8, line_color='green', legend_label='GX1')\n",
    "line_gy1 = plot1.line('x', 'y', source=source5, line_width=2, line_alpha=0.8, line_color='yellow', legend_label='GY1')\n",
    "line_gz1 = plot1.line('x', 'y', source=source6, line_width=2, line_alpha=0.8, line_color='pink', legend_label='GZ1')\n",
    "\n",
    "\n",
    "\n",
    "# plot2 = figure(plot_height=300, title=\"Channel AY1\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "# line = plot2.line('x', 'y', source=source2, line_width=2, line_alpha=0.8)\n",
    "\n",
    "# plot3 = figure(plot_height=300, title=\"Channel AZ1\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "# line = plot3.line('x', 'y', source=source3, line_width=2, line_alpha=0.8)\n",
    "\n",
    "# plot4 = figure(plot_height=300, title=\"Channel GX1\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "# line = plot4.line('x', 'y', source=source4, line_width=2, line_alpha=0.8)\n",
    "\n",
    "# plot5 = figure(plot_height=300, title=\"Channel GY1\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "# line = plot5.line('x', 'y', source=source5, line_width=2, line_alpha=0.8)\n",
    "\n",
    "# plot6 = figure(plot_height=300, title=\"Channel GZ1\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "# line = plot6.line('x', 'y', source=source6, line_width=2, line_alpha=0.8)\n",
    "\n",
    "plot7 = figure(height=150, title=\"MPU2\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "line_ax2 = plot7.line('x', 'y', source=source7, line_width=2, line_alpha=0.8, line_color='black', legend_label='AX2')\n",
    "line_ay2 = plot7.line('x', 'y', source=source8, line_width=2, line_alpha=0.8, line_color='blue', legend_label='AY2')\n",
    "line_az2 = plot7.line('x', 'y', source=source9, line_width=2, line_alpha=0.8, line_color='red', legend_label='AZ2')\n",
    "line_gx2 = plot7.line('x', 'y', source=source10, line_width=2, line_alpha=0.8, line_color='green', legend_label='GX2')\n",
    "line_gy2 = plot7.line('x', 'y', source=source11, line_width=2, line_alpha=0.8, line_color='yellow', legend_label='GY2')\n",
    "line_gz2 = plot7.line('x', 'y', source=source12, line_width=2, line_alpha=0.8, line_color='pink', legend_label='GZ2')\n",
    "\n",
    "\n",
    "# plot8 = figure(plot_height=300, title=\"Channel AY2\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "# line = plot8.line('x', 'y', source=source8, line_width=2, line_alpha=0.8)\n",
    "\n",
    "# plot9 = figure(plot_height=300, title=\"Channel AZ2\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "# line = plot9.line('x', 'y', source=source9, line_width=2, line_alpha=0.8)\n",
    "\n",
    "# plot10 = figure(plot_height=300, title=\"Channel GX2\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "# line = plot10.line('x', 'y', source=source10, line_width=2, line_alpha=0.8)\n",
    "\n",
    "# plot11 = figure(plot_height=300, title=\"Channel GY2\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "# line = plot11.line('x', 'y', source=source11, line_width=2, line_alpha=0.8)\n",
    "\n",
    "# plot12 = figure(plot_height=300, title=\"Channel GZ2\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "# line = plot12.line('x', 'y', source=source12, line_width=2, line_alpha=0.8)\n",
    "\n",
    "plot13 = figure(height=150, title=\"Predictions\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "plot13.add_glyph(Segment(x0=0, y0=0.5, x1=1, y1=0.5, line_color='blue', line_width=2))\n",
    "plot13.y_range = Range1d(0, 1)\n",
    "line = plot13.line('x', 'y', source=source13, line_width=2, line_alpha=0.8, line_color='black')\n",
    "\n",
    "\n",
    "plots.append(plot1)\n",
    "plots.append(plot7)\n",
    "plots.append(plot13)\n",
    "# plots.append(plot3)\n",
    "# plots.append(plot4)\n",
    "# plots.append(plot5)\n",
    "# plots.append(plot6)\n",
    "# plots.append(plot7)\n",
    "# plots.append(plot8)\n",
    "# plots.append(plot9)\n",
    "# plots.append(plot10)\n",
    "# plots.append(plot11)\n",
    "# plots.append(plot12)\n",
    "\n",
    "\n",
    "grid = layout(plots, sizing_mode='scale_width')\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "show(grid, notebook_handle=True)\n",
    "\n",
    "\n",
    "test_mode = config['env']['test']\n",
    "if not test_mode:\n",
    "    connect_mqtt_server()\n",
    "\n",
    "while test_mode:\n",
    "    test_data = []\n",
    "    for i in range(30):\n",
    "        test_data.append([\n",
    "            '('+ datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\") + ')', \n",
    "            random.uniform(1.7, 2),\n",
    "            random.uniform(6.7, 7),\n",
    "            random.uniform(-7, -6.6),\n",
    "            random.uniform(-4, 2),\n",
    "            random.uniform(-2, 2),\n",
    "            random.uniform(-8, -3),\n",
    "            random.uniform(0, 0.3),\n",
    "            random.uniform(9, 9.3),\n",
    "            random.uniform(-4.3, -4),\n",
    "            random.uniform(0, 5),\n",
    "            random.uniform(-2, 2),\n",
    "            random.uniform(-6, -4),\n",
    "        ])\n",
    "    update(test_data)\n",
    "    time.sleep(0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee53bc1d-3f4f-488d-811c-a7b16f0b2f57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
