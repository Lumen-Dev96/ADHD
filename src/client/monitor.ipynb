{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9445cd2a-51b8-476c-8b9b-7e0ced507d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource, Segment, Range1d\n",
    "from bokeh.layouts import layout\n",
    "from bokeh.io import push_notebook, show, output_notebook\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import sys\n",
    "import pandas as pd\n",
    "import paho.mqtt.client as mqtt\n",
    "import time\n",
    "from math import *\n",
    "import random\n",
    "import _thread\n",
    "import yaml\n",
    "import ujson\n",
    "import datetime\n",
    "import uarray\n",
    "\n",
    "\n",
    "\n",
    "# 更新函數，每次呼叫時更新數據\n",
    "def update(message):\n",
    "    global x, y_data, grap_id, rawData, record_count, predict_start\n",
    "    \n",
    "    # 解碼 MQTT 數據\n",
    "    if test_mode:\n",
    "        data = message\n",
    "    else:\n",
    "        payload = message.payload.decode()\n",
    "        # data = eval(payload)\n",
    "        data = ujson.loads(payload)\n",
    "        # print(data)\n",
    "\n",
    "    \n",
    "    mqData = np.array(data)\n",
    "    rawData.append(mqData)\n",
    "    # print(mqData)\n",
    "\n",
    "    # times = mqData[:, 0]\n",
    "    channel1 = mqData[:, 1]\n",
    "    channel2 = mqData[:, 2]\n",
    "    channel3 = mqData[:, 3]\n",
    "    channel4 = mqData[:, 4]\n",
    "    channel5 = mqData[:, 5]\n",
    "    channel6 = mqData[:, 6]\n",
    "    channel7 = mqData[:, 7]\n",
    "    channel8 = mqData[:, 8]\n",
    "    channel9 = mqData[:, 9]\n",
    "    channel10 = mqData[:, 10]\n",
    "    channel11 = mqData[:, 11]\n",
    "    channel12 = mqData[:, 12]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    ### 使用模型进行预测 ###\n",
    "\n",
    "    # 使用測試隨機數\n",
    "    # ranges = np.array([[1.7, 2], [6.7, 7], [-7, -6.6], [-4, 2], [-2, 2], [-8, -3], [0, 0.3], [9, 9.3], [-4.3, -4], [0, 5], [-2, 2], [-6, -4]])\n",
    "    # 使用 numpy.random.uniform 生成具有不同範圍的數據\n",
    "    # dataForTest = np.column_stack([np.random.uniform(low=low, high=high, size=30) for low, high in ranges])\n",
    "    # print('-----------------')\n",
    "    # dataForTest = dataForTest[np.newaxis, ...]\n",
    "    # print('transforming test random data shape:', dataForTest.shape)\n",
    "    # print('data for test:', dataForTest)\n",
    "\n",
    "\n",
    "    # 使用訓練數據展示結果\n",
    "    # dataForTrain = trained_data_x[record_count * data_length : record_count * data_length + data_length, :]\n",
    "    # dataForTrain = dataForTrain[np.newaxis, ...]\n",
    "    # print('transforming train data shape:', dataForTrain.shape)\n",
    "    # print('data for train:', dataForTrain)\n",
    "\n",
    "    if (record_count + 1) * data_length >= (predict_start + 1) * window_size + window_size:\n",
    "    # if record_count > 1:\n",
    "        # 有數據量滿足最小2倍窗口才能開始推理\n",
    "        npRawData = np.concatenate(rawData, axis=0)\n",
    "        fifoData = np.empty((window_size, window_size, 12), dtype=float)\n",
    "        for i in range(window_size):\n",
    "            tmp = npRawData[predict_start * window_size + i : predict_start * window_size + window_size + i, 1:]\n",
    "            # print('tmp data shape:', tmp.shape)\n",
    "            tmp = tmp.astype(np.float64)\n",
    "            # print('tmp data:', tmp)\n",
    "            if is_normalize:\n",
    "                fifoData[:, i, :] = custom_normalize(tmp)\n",
    "            else:\n",
    "                fifoData[:, i, :] = tmp\n",
    "            # print('fifo:', fifoData)\n",
    "\n",
    "\n",
    "        # print('transforming fifo data shape:', fifoData.shape)\n",
    "        # print('fifo:', fifoData)\n",
    "        # print('np raw data shape:', npRawData.shape)\n",
    "        # print(predict_start * window_size + window_size)\n",
    "\n",
    "        y_pred = model.predict(fifoData, verbose=0)\n",
    "        # predictions.append(y_pred)\n",
    "\n",
    "        # 将预测结果转换为 NumPy 数组\n",
    "        # predictionsNp = np.array(predictions)\n",
    "        predictionsNp = np.array(y_pred)\n",
    "        predictionsNp = predictionsNp.flatten()\n",
    "\n",
    "        # 判斷是否過動\n",
    "        hyperActionCount = np.sum(predictionsNp >= 0.5)\n",
    "        if hyperActionCount >= 85 and enable_shock and not test_mode:\n",
    "            publish()\n",
    "        \n",
    "        # print('---------')\n",
    "        # print('y_pred:', y_pred)\n",
    "        # print('y_pred shape:', y_pred.shape)\n",
    "        # print('------------------')\n",
    "        # print('predictoin NP:', predictionsNp)\n",
    "        # print('predictions shape:', predictionsNp.shape)\n",
    "        # 提取预测类别的最大概率 >0.5 => 1, <0.5 => 0\n",
    "        # predicted_classes = predictionsNp[-1]\n",
    "        # 只會有一個結果, 值為 0 或者 1\n",
    "        # print(predicted_classes[0])\n",
    "        # prediction_label = round(predicted_classes[0])\n",
    "        # print('predicted_classes', predicted_classes)\n",
    "        # print('prediction_label', prediction_label)\n",
    "        # print('++++++++++++++++')\n",
    "        # print(predict_start * window_size, predict_start * window_size + window_size)\n",
    "        # print('++++++++++++++++')\n",
    "        predict_start += 1\n",
    "        source13.stream({'x': np.arange(predict_start * window_size, predict_start * window_size + window_size), 'y': predictionsNp})\n",
    "        separation.stream({'x': np.arange(predict_start * window_size, predict_start * window_size + window_size), 'y': np.full(window_size, 0.5)})\n",
    "\n",
    "\n",
    "\n",
    "    # 更新數據源的數據\n",
    "    source1.stream({'x':np.arange(grap_id, grap_id + data_length), 'y':channel1})\n",
    "    source2.stream({'x':np.arange(grap_id, grap_id + data_length), 'y':channel2})\n",
    "    source3.stream({'x':np.arange(grap_id, grap_id + data_length), 'y':channel3})\n",
    "    source4.stream({'x':np.arange(grap_id, grap_id + data_length), 'y':channel4})\n",
    "    source5.stream({'x':np.arange(grap_id, grap_id + data_length), 'y':channel5})\n",
    "    source6.stream({'x':np.arange(grap_id, grap_id + data_length), 'y':channel6})\n",
    "    source7.stream({'x':np.arange(grap_id, grap_id + data_length), 'y':channel7})\n",
    "    source8.stream({'x':np.arange(grap_id, grap_id + data_length), 'y':channel8})\n",
    "    source9.stream({'x':np.arange(grap_id, grap_id + data_length), 'y':channel9})\n",
    "    source10.stream({'x':np.arange(grap_id, grap_id + data_length), 'y':channel10})\n",
    "    source11.stream({'x':np.arange(grap_id, grap_id + data_length), 'y':channel11})\n",
    "    source12.stream({'x':np.arange(grap_id, grap_id + data_length), 'y':channel12})\n",
    "\n",
    "    # Update ID\n",
    "    grap_id += data_length\n",
    "    record_count = record_count + 1\n",
    "\n",
    "    # print('predictions count', predict_start)\n",
    "    # print('update count', record_count)\n",
    "\n",
    "\n",
    "    if export_csv and record_count % 700 == 0:\n",
    "        exportCSV()\n",
    "\n",
    "    push_notebook()\n",
    "\n",
    "    \n",
    "\n",
    "def exportCSV():\n",
    "    global rawData\n",
    "    csvData = np.concatenate(rawData, axis=0)\n",
    "    timestamps = csvData[:, 0]\n",
    "    ax1 = csvData[:, 1]\n",
    "    ay1 = csvData[:, 2]\n",
    "    az1 = csvData[:, 3]\n",
    "    gx1 = csvData[:, 4]\n",
    "    gy1 = csvData[:, 5]\n",
    "    gz1 = csvData[:, 6]\n",
    "\n",
    "    ax2 = csvData[:, 7] \n",
    "    ay2 = csvData[:, 8]\n",
    "    az2 = csvData[:, 9]\n",
    "    gx2 = csvData[:, 10]\n",
    "    gy2 = csvData[:, 11]\n",
    "    gz2 = csvData[:, 12]\n",
    "\n",
    "    # 将时间戳转换为本地时间元组\n",
    "    # new_times = np.vectorize(transformTimestamps)(timestamps)\n",
    "\n",
    "    # dictionary of lists\n",
    "    dict = {'Timestamps': timestamps, 'Ax1': ax1, 'Ay1': ay1, 'Az1': az1, 'Gx1': gx1, 'Gy1': gy1, 'Gz1': gz1, 'Ax2': ax2, 'Ay2': ay2, 'Az2': az2, 'Gx2': gx2, 'Gy2': gy2, 'Gz2': gz2}\n",
    "        \n",
    "    df = pd.DataFrame(dict)\n",
    "    filename = 'output.csv'\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "\n",
    "def on_connect(client, userdata, flags, rc):\n",
    "    if rc == 0:\n",
    "        print(\"Connected to MQTT broker\")\n",
    "    else:\n",
    "        print(\"Failed to connect, return code %d\\n\", rc)\n",
    "\n",
    "def on_message(client, userdata, message):\n",
    "    # print(\"Received data from esp32 via MQTT\")\n",
    "    update(message)\n",
    "    # print(\"Received message on topic %s: %s\" % (message.topic, message.payload.decode()))\n",
    "\n",
    "def publish():\n",
    "    topic = 'Command'\n",
    "    message = 'vibrator'\n",
    "    result = client.publish(topic, ujson.dumps(message))\n",
    "    status = result[0]\n",
    "    # if status == 0:\n",
    "    #     print('Command publish successfully')\n",
    "    # else:\n",
    "    #     print('Command publish failed')\n",
    "\n",
    "def connect_mqtt_server():\n",
    "    # 连接MQTT代理\n",
    "    # broker_address = \"broker.emqx.io\"\n",
    "    broker_address = config['mqtt']['broker_address']\n",
    "    # broker_address = \"broker.mqttdashboard.com\"\n",
    "    # broker_address = \"test.mosquitto.org\"\n",
    "    port = config['mqtt']['port']\n",
    "    username = config['mqtt']['username']\n",
    "    password = config['mqtt']['password']\n",
    "\n",
    "    client = mqtt.Client()\n",
    "    client.username_pw_set(username, password)\n",
    "    client.on_connect = on_connect\n",
    "    client.on_message = on_message\n",
    "\n",
    "    client.connect(broker_address, port)\n",
    "\n",
    "    # 订阅消息\n",
    "    client.subscribe(topic)\n",
    "\n",
    "    _thread.start_new_thread(client.loop_forever, (1,))\n",
    "\n",
    "    return client\n",
    "\n",
    "\n",
    "def normalize(X):    \n",
    "    \"\"\"    对矩阵X进行0-1标准化    \"\"\"    \n",
    "    X_min = np.min(X, axis=0)    \n",
    "    X_max = np.max(X, axis=0)    \n",
    "    X_norm = (X - X_min) / (X_max - X_min)    \n",
    "    return X_norm\n",
    "\n",
    "\n",
    "def z_score_normalize(data):    \n",
    "    mean = np.mean(data, axis=0)    \n",
    "    std_dev = np.std(data, axis=0)    \n",
    "    normalized_data = (data - mean) / std_dev    \n",
    "    return normalized_data\n",
    "\n",
    "def custom_normalize(data):\n",
    "    mean = np.array([\n",
    "        1.71372359,\n",
    "        -1.309678406,\n",
    "        9.363899948,\n",
    "        -7.158961311,\n",
    "        -0.006600919,\n",
    "        0.286749953,\n",
    "        -7.735658716,\n",
    "        1.051930921,\n",
    "        -5.200263283,\n",
    "        -2.892873396,\n",
    "        1.120912099,\n",
    "        0.893979415\n",
    "    ])\n",
    "    std = np.array([\n",
    "        1.709795276,\n",
    "        1.95560962,\n",
    "        0.902204529,\n",
    "        8.423791982,\n",
    "        8.045305195,\n",
    "        9.653637638,\n",
    "        0.937653695,\n",
    "        1.022502025,\n",
    "        1.765456977,\n",
    "        8.940407294,\n",
    "        8.906588446,\n",
    "        8.375117074\n",
    "    ])\n",
    "\n",
    "    for i in range(data_channels):  # 迭代列\n",
    "        data[:, i] = (data[:, i] - mean[i]) / std[i]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "################################ Main Program ################################\n",
    "\n",
    "# 初始化數據/設定\n",
    "with open('./config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "data_length = config['data']['length']\n",
    "data_channels = config['data']['channels']\n",
    "window_size = config['data']['window_size']\n",
    "trained_data_path = config['data']['train_data_path']\n",
    "topic = config['mqtt']['topic']\n",
    "export_csv = config['env']['export_csv']\n",
    "is_normalize = config['data']['normalize']\n",
    "enable_shock = config['device']['enable_shock']\n",
    "\n",
    "\n",
    "x = np.arange(data_length)\n",
    "\n",
    "y_data = [np.zeros(data_length) for _ in range(data_channels + 1)]\n",
    "\n",
    "grap_id = 0\n",
    "\n",
    "record_count = 0\n",
    "\n",
    "rawData = []\n",
    "\n",
    "predict_start = 0\n",
    "\n",
    "predict_x = np.arange(window_size)\n",
    "predict_y = np.zeros(window_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trained_data = pd.read_csv(trained_data_path + 'a1_1.csv')\n",
    "trained_data_x = trained_data.iloc[:, 1:-1].values\n",
    "\n",
    "\n",
    "########### LOAD MODEL ###############\n",
    "predictions = []\n",
    "model_path = config['model']['pb_path']\n",
    "model = load_model(model_path, compile=False)\n",
    "model.compile()\n",
    "########### LOAD MODEL ###############\n",
    "\n",
    "\n",
    "\n",
    "source1 = ColumnDataSource(data={'x': [], 'y': []})\n",
    "source2 = ColumnDataSource(data={'x': [], 'y': []})\n",
    "source3 = ColumnDataSource(data={'x': [], 'y': []})\n",
    "source4 = ColumnDataSource(data={'x': [], 'y': []})\n",
    "source5 = ColumnDataSource(data={'x': [], 'y': []})\n",
    "source6 = ColumnDataSource(data={'x': [], 'y': []})\n",
    "\n",
    "source7 = ColumnDataSource(data={'x': [], 'y': []})\n",
    "source8 = ColumnDataSource(data={'x': [], 'y': []})\n",
    "source9 = ColumnDataSource(data={'x': [], 'y': []})\n",
    "source10 = ColumnDataSource(data={'x': [], 'y': []})\n",
    "source11 = ColumnDataSource(data={'x': [], 'y': []})\n",
    "source12 = ColumnDataSource(data={'x': [], 'y': []})\n",
    "source13 = ColumnDataSource(data={'x': [], 'y': []})\n",
    "separation = ColumnDataSource(data={'x': [], 'y': []})\n",
    "\n",
    "\n",
    "\n",
    "# 創建 Bokeh 的線型圖\n",
    "plots = []\n",
    "plot1 = figure(height=150, title=\"MPU1\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "line_ax1 = plot1.line('x', 'y', source=source1, line_width=2, line_alpha=0.8, line_color='black', legend_label='AX1')\n",
    "line_ay1 = plot1.line('x', 'y', source=source2, line_width=2, line_alpha=0.8, line_color='blue', legend_label='AY1')\n",
    "line_az1 = plot1.line('x', 'y', source=source3, line_width=2, line_alpha=0.8, line_color='red', legend_label='AZ1')\n",
    "line_gx1 = plot1.line('x', 'y', source=source4, line_width=2, line_alpha=0.8, line_color='green', legend_label='GX1')\n",
    "line_gy1 = plot1.line('x', 'y', source=source5, line_width=2, line_alpha=0.8, line_color='yellow', legend_label='GY1')\n",
    "line_gz1 = plot1.line('x', 'y', source=source6, line_width=2, line_alpha=0.8, line_color='pink', legend_label='GZ1')\n",
    "\n",
    "\n",
    "\n",
    "# plot2 = figure(plot_height=300, title=\"Channel AY1\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "# line = plot2.line('x', 'y', source=source2, line_width=2, line_alpha=0.8)\n",
    "\n",
    "# plot3 = figure(plot_height=300, title=\"Channel AZ1\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "# line = plot3.line('x', 'y', source=source3, line_width=2, line_alpha=0.8)\n",
    "\n",
    "# plot4 = figure(plot_height=300, title=\"Channel GX1\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "# line = plot4.line('x', 'y', source=source4, line_width=2, line_alpha=0.8)\n",
    "\n",
    "# plot5 = figure(plot_height=300, title=\"Channel GY1\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "# line = plot5.line('x', 'y', source=source5, line_width=2, line_alpha=0.8)\n",
    "\n",
    "# plot6 = figure(plot_height=300, title=\"Channel GZ1\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "# line = plot6.line('x', 'y', source=source6, line_width=2, line_alpha=0.8)\n",
    "\n",
    "plot7 = figure(height=150, title=\"MPU2\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "line_ax2 = plot7.line('x', 'y', source=source7, line_width=2, line_alpha=0.8, line_color='black', legend_label='AX2')\n",
    "line_ay2 = plot7.line('x', 'y', source=source8, line_width=2, line_alpha=0.8, line_color='blue', legend_label='AY2')\n",
    "line_az2 = plot7.line('x', 'y', source=source9, line_width=2, line_alpha=0.8, line_color='red', legend_label='AZ2')\n",
    "line_gx2 = plot7.line('x', 'y', source=source10, line_width=2, line_alpha=0.8, line_color='green', legend_label='GX2')\n",
    "line_gy2 = plot7.line('x', 'y', source=source11, line_width=2, line_alpha=0.8, line_color='yellow', legend_label='GY2')\n",
    "line_gz2 = plot7.line('x', 'y', source=source12, line_width=2, line_alpha=0.8, line_color='pink', legend_label='GZ2')\n",
    "\n",
    "\n",
    "# plot8 = figure(plot_height=300, title=\"Channel AY2\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "# line = plot8.line('x', 'y', source=source8, line_width=2, line_alpha=0.8)\n",
    "\n",
    "# plot9 = figure(plot_height=300, title=\"Channel AZ2\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "# line = plot9.line('x', 'y', source=source9, line_width=2, line_alpha=0.8)\n",
    "\n",
    "# plot10 = figure(plot_height=300, title=\"Channel GX2\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "# line = plot10.line('x', 'y', source=source10, line_width=2, line_alpha=0.8)\n",
    "\n",
    "# plot11 = figure(plot_height=300, title=\"Channel GY2\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "# line = plot11.line('x', 'y', source=source11, line_width=2, line_alpha=0.8)\n",
    "\n",
    "# plot12 = figure(plot_height=300, title=\"Channel GZ2\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "# line = plot12.line('x', 'y', source=source12, line_width=2, line_alpha=0.8)\n",
    "\n",
    "plot13 = figure(height=150, title=\"Predictions\", tools=\"crosshair,pan,reset,save,wheel_zoom\")\n",
    "line = plot13.line('x', 'y', source=separation, line_width=2, line_alpha=0.8, line_color='blue')\n",
    "plot13.y_range = Range1d(0, 1)\n",
    "line = plot13.line('x', 'y', source=source13, line_width=2, line_alpha=0.8, line_color='orange')\n",
    "\n",
    "\n",
    "plots.append(plot1)\n",
    "plots.append(plot7)\n",
    "plots.append(plot13)\n",
    "# plots.append(plot3)\n",
    "# plots.append(plot4)\n",
    "# plots.append(plot5)\n",
    "# plots.append(plot6)\n",
    "# plots.append(plot7)\n",
    "# plots.append(plot8)\n",
    "# plots.append(plot9)\n",
    "# plots.append(plot10)\n",
    "# plots.append(plot11)\n",
    "# plots.append(plot12)\n",
    "\n",
    "\n",
    "grid = layout(plots, sizing_mode='scale_width')\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "show(grid, notebook_handle=True)\n",
    "\n",
    "\n",
    "test_mode = config['env']['test']\n",
    "if not test_mode:\n",
    "    client = connect_mqtt_server()\n",
    "\n",
    "while test_mode:\n",
    "    test_data = []\n",
    "    for i in range(data_length):\n",
    "        test_data.append([\n",
    "            '('+ datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\") + ')', \n",
    "            random.uniform(1.7, 2),\n",
    "            random.uniform(6.7, 7),\n",
    "            random.uniform(-7, -6.6),\n",
    "            random.uniform(-4, 2),\n",
    "            random.uniform(-2, 2),\n",
    "            random.uniform(-8, -3),\n",
    "            random.uniform(0, 0.3),\n",
    "            random.uniform(9, 9.3),\n",
    "            random.uniform(-4.3, -4),\n",
    "            random.uniform(0, 5),\n",
    "            random.uniform(-2, 2),\n",
    "            random.uniform(-6, -4),\n",
    "        ])\n",
    "    update(test_data)\n",
    "    time.sleep(0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee53bc1d-3f4f-488d-811c-a7b16f0b2f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57609063-14a3-480f-8de1-e8fc316b1ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
